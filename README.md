# URL Status Analyzer

There are two python scripts. 
•	checkUrlStatusPersistData.py
•	generate_Daily_UrlStatus_Report.py

The file which holds the urls has been placed in /root/url 
checkUrlStatusPersistData.py is to check the URL Availability, HTTP status code, response time & then write the data to the DB.
generate_Daily_UrlStatus_Report.py generate the daily report by pulling last 96 records from DB ( the first python script is scheduled in cron , in a such way that, it would be running every 15 minutes and in a day it would run 96 times and create 96 documents in the DB correspondingly. ) every day at 23:50 .
The report is generated with the date appended with the file name urlstatus_report_13042020.html

![image](https://github.com/emjeev/URL-Status-Analyzer/assets/61203867/06dd563c-951e-4b12-8d4f-cdb816b38333)


Crontab Schedule :
![image](https://github.com/emjeev/URL-Status-Analyzer/assets/61203867/bc42836f-a43c-4567-a6c4-58b9cfce9ac2)

 
DB, Collections:

![image](https://github.com/emjeev/URL-Status-Analyzer/assets/61203867/f816f80c-2587-48a8-8cc9-de01b498bb9a)

1.	This script will be executed periodically.
    The crontab is used to schedule the scripts periodically. Details are given later in the documentation.
2.	List of URLs is kept in a text file
   List of URLs kept in a text file in a specified path.
3.	You choose report format
For reporting chosen HTML file format.  One of the PY script will generate the daily report by reading data from the DB for the past 24 hours and will build an HTML report out of it. As of now the report is generated in the system itself, if required can send as an attachment in a mail.
4.	You choose programming language.
   Python is used for the development of scripts.
5.	Design report format such that long term trends can be analyzed
   As the data is stored in DB, this would be available for long term for the trend analysis. The data can be retrieved based on any criteria. 
6.	Demonstrate/ Propose methods of analyzing long term trends
   Based on the various data points, the long-term trends can be analyzed. As the data is available in DB, the trend can be analyzed by retrieving the data from DB according to the required business logic. I have implemented based on the URL status. If the URL status is DOWN, it would send an alert with the required details to notify the user/s.

![image](https://github.com/emjeev/URL-Status-Analyzer/assets/61203867/5eeabc63-008b-44b0-9ce7-aa1c03d696e1)

7.	Demonstrate/ Propose methods of setting up monitoring from different regions of the world.
   For monitoring the URLs from different regions of the world, these PY scripts & the hosts file can be deployed as an Amazon Lambda Package and schedule the scripts accordingly. I have implemented the challenge in a conventional way hence hasn’t used in any cloud service. If required, this can be implemented via Lambda service also.
8.	Demonstrate how alerts can be generated.
The script is dealing with various data during URL check, ie , Status ( UP/DOWN) , HTTP Response Code , Response Time etc. The alerts can be generated by referring any of these components.

![image](https://github.com/emjeev/URL-Status-Analyzer/assets/61203867/0eef10d4-8068-4e9e-9819-dac68f72556a)

9.	Consider scaling of this tool to monitor 1000s of URLs.
The scaling can be achieved by python multi-threading capability also by Lambda Packaging.
10.	Bonus: measure response time for these sites along with long term trends.
      The response time is captured and saved in the db which will ensure long term trend analysis.





